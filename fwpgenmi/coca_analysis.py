import os
import shutil
import argparse
import itertools
import pandas as pd
from tempfile import mkdtemp
from collections import OrderedDict

import matplotlib.pyplot as plt
#from IPython.display import HTML
from lifelines import KaplanMeierFitter
from lifelines.statistics import multivariate_logrank_test

from knspreadsheetstransformation.spreadsheets_transformation_toolbox import \
    get_cluster_binary_dataframe

from fwpgenmi.KnowEng import do_clustering, fetch_network, fetch_network_metadata
from fwpgenmi.KnowEng import get_path_to_newest_file_having_prefix, round_to_1

from fwpgenmi.io_cfg import results_dir, input_dir
from fwpgenmi.io_cfg import make_abspath, read_yaml
# -------------------------------- #
#        Get the Arguments         #
# -------------------------------- #
parser = argparse.ArgumentParser()
parser.add_argument('--rank', action="store", type=int, default=-1)
parser.add_argument('--parallel', default=False, action='store_true', 
                    help= "running configs in parallel. If this option is True then the rank/job_id in the batch job submission should be provided using --rank argument.")
parser.add_argument('--config_path', type=str, required=True) # e.g., 07_cfg_coca_analysis.yml
args = parser.parse_args()

# -------------------------------- #
#         Get the Configs          #
# -------------------------------- #
cfg_path = args.config_path
config_dict = read_yaml.load(cfg_path)

NETWORK_DIR_PATH= config_dict.get('NETWORK_DIR_PATH', 'network')
NETWORK_DIR_PATH = make_abspath(NETWORK_DIR_PATH, results_dir)

NUM_CPUS= config_dict.get('NUM_CPUS', 2)
gene_counts= config_dict.get('gene_counts', [20, 50, 70, 100])
bootstrap_ratio= config_dict.get('bootstrap_ratio', 0.8)
num_bootstrap= config_dict.get('num_bootstrap', 10)
num_clusters= config_dict.get('num_clusters', [2, 3, 4])
network_influences= config_dict.get('network_influences', [0.1, 0.2, 0.3, 0.5, 0.6, 0.8])
network_types= config_dict.get('network_types',  [f'{NETWORK_DIR_PATH}/Property/9606/PPI_complex/9606.PPI_complex.edge',
                                                  f'{NETWORK_DIR_PATH}/Property/9606/gene_ontology/9606.gene_ontology.edge', 
                                                  f'{NETWORK_DIR_PATH}/Property/9606/enrichr_pathway/9606.enrichr_pathway.edge'])
if 'input_data_dirs' in config_dict.keys():
    input_data_dirs= config_dict['input_data_dirs']
    for i in range(len(input_data_dirs)):
        input_datadir = input_data_dirs[i]
        input_datadir = make_abspath(input_datadir, results_dir)
        input_data_dirs[i] = input_datadir
else:
    # set to default path to coca inputs generated by coca_input_gen.py
    input_data_dirs= [f'{results_dir}/coca_results/coca_input/mediator_genes/AllGenes/AllEvidGenes']
    for i in gene_counts:
        input_data_dirs.append(f'{results_dir}/coca_results/coca_input/mediator_genes/postOddsRatio/Separate/down/postOddsRatio_top{i}')
        input_data_dirs.append(f'{results_dir}/coca_results/coca_input/mediator_genes/postOddsRatio/Separate/up/postOddsRatio_top{i}')
        input_data_dirs.append(f'{results_dir}/coca_results/coca_input/mediator_genes/RatioOfPostOddsRatio/Separate/down/topGene{i}_topTF5')
        input_data_dirs.append(f'{results_dir}/coca_results/coca_input/mediator_genes/RatioOfPostOddsRatio/Separate/up/topGene{i}_topTF5')

        input_data_dirs.append(f'{results_dir}/coca_results/coca_input/mediator_genes/postOddsRatio/Union/postOddsRatio_top{i}')
        input_data_dirs.append(f'{results_dir}/coca_results/coca_input/mediator_genes/RatioOfPostOddsRatio/Union/topGene{i}_topTF5')
        #input_data_dirs.append(f'../COCA_input/DEGenes/DEGenes_top{i}')

# get the networks
for interaction_network_edge_file_path in network_types:
    fetch_network(interaction_network_edge_file_path, NETWORK_DIR_PATH)
            
curr_rank= -1
for INPUT_DATA_DIR_PATH in input_data_dirs:
    if args.parallel:
        curr_rank = curr_rank + 1
        if not (curr_rank == args.rank or args.rank == -1):
            continue
    
    OUTPUT_DATA_DIR_PATH = os.path.join(INPUT_DATA_DIR_PATH, 'results/')
    merge_nwtype_nwInf = list(itertools.product(network_influences, network_types))

    ctr = -1
    for num_cluster in num_clusters:
        for ind, (network_influence, network_type) in enumerate(merge_nwtype_nwInf):
            ctr= ctr+1

            OUTPUT_DATA_DIR_PATH_ = os.path.join(OUTPUT_DATA_DIR_PATH, str(ctr))
            cluster_result_paths= OrderedDict([
                ('GeneExpr', os.path.join(OUTPUT_DATA_DIR_PATH_, 'clustering_gene')),
                ('SomaMut', os.path.join(OUTPUT_DATA_DIR_PATH_, 'clustering_mut')), 
                ('miR', os.path.join(OUTPUT_DATA_DIR_PATH_, 'clustering_miR'))])


            # mirna expression clustering
            CLUSTERING_DIR_PATH = cluster_result_paths['miR']
            do_clustering(os.path.join(INPUT_DATA_DIR_PATH, 'miRExprXPatient'),
                          os.path.join(INPUT_DATA_DIR_PATH, 'PatientXSurvival'),
                          CLUSTERING_DIR_PATH, num_cluster, None, None, None, 
                          num_bootstrap, bootstrap_ratio, NUM_CPUS)

            # gene expression clustering 
            CLUSTERING_DIR_PATH = cluster_result_paths['GeneExpr']
            do_clustering(os.path.join(INPUT_DATA_DIR_PATH, 'geneExprXPatient'),
                          os.path.join(INPUT_DATA_DIR_PATH, 'PatientXSurvival'),
                          CLUSTERING_DIR_PATH, num_cluster, None, None, None,
                          num_bootstrap, bootstrap_ratio, NUM_CPUS)

            # mutation clustering using network
            CLUSTERING_DIR_PATH = cluster_result_paths['SomaMut']
            do_clustering(os.path.join(INPUT_DATA_DIR_PATH, 'geneXpatient_somatic'),
                          os.path.join(INPUT_DATA_DIR_PATH, 'PatientXSurvival'), 
                          CLUSTERING_DIR_PATH, num_cluster, '9606',network_type,
                          network_influence, num_bootstrap, bootstrap_ratio, NUM_CPUS)

            # Coca Analysis:
            raw_coca_inputs= []
            for key in cluster_result_paths:
                addr= get_path_to_newest_file_having_prefix(cluster_result_paths[key], 'samples_label_by_cluster')
                raw_coca_inputs.append(addr)


            ind= -1
            while ind < len(raw_coca_inputs):
                if ind == -1:
                    tag= 'allOmics'
                    raw_coca_inputs_cp = raw_coca_inputs[:]
                else:
                    tag= list(cluster_result_paths.keys())[ind]
                    raw_coca_inputs_cp = raw_coca_inputs[:]
                    raw_coca_inputs_cp.pop(ind)

                ind= ind+1

                # assemble the raw inputs into a single file formatted like an omics file
                coca_results_dir= os.path.join(OUTPUT_DATA_DIR_PATH_, 'coca-'+tag)
                os.makedirs(coca_results_dir, exist_ok=True)
                coca_input_file_path = os.path.join(coca_results_dir, 'input.tsv')
                temp_dir_path = mkdtemp()
                try:
                    for input in raw_coca_inputs_cp:
                        shutil.copy(input, temp_dir_path)
                    coca_input_df = get_cluster_binary_dataframe(\
                      [os.path.basename(input) for input in raw_coca_inputs_cp], temp_dir_path).T
                    coca_input_df.to_csv(coca_input_file_path, sep='\t')
                finally:
                    shutil.rmtree(temp_dir_path)

                do_clustering(coca_input_file_path,
                              os.path.join(INPUT_DATA_DIR_PATH, 'PatientXSurvival'),
                              coca_results_dir, num_cluster, None, None, None, 100, 0.8, NUM_CPUS)  

                # Survival Analysis:
                # https://lifelines.readthedocs.io/en/latest/Examples.html

                phenotype_df = pd.read_csv(\
                                           os.path.join(INPUT_DATA_DIR_PATH, 'PatientXSurvival'), \
                                           sep='\t', index_col=0, header=0)

                # load the cluster assignments
                cluster_labels_file_path = get_path_to_newest_file_having_prefix(\
                                                                                 coca_results_dir, 'samples_label_by_cluster')
                cluster_labels_df = pd.read_csv(cluster_labels_file_path, 
                                                sep='\t', index_col=0, header=None, names=['cluster'])
                # reorder cluster_labels_df to match the sample order in phenotype_df

                combined_df = pd.concat([phenotype_df['_EVENT'], phenotype_df['_OS'], \
                                         cluster_labels_df], axis=1, sort=True)

                # retain only the samples that have a time and a cluster
                combined_df.dropna(subset=['_OS', 'cluster'], inplace=True)

                # fill missing values in event (0, for censored)
                combined_df['_EVENT'].fillna(value=0, inplace=True)

                # calculate p-value
                test_stats = multivariate_logrank_test(combined_df['_OS'].values, \
                                                       combined_df['cluster'].values, combined_df['_EVENT'].values)

                # draw plot
                fig = plt.figure()
                ax = fig.gca()
                kmf = KaplanMeierFitter()

                for name, grouped_df in combined_df.groupby('cluster'):
                    kmf.fit(grouped_df["_OS"], grouped_df["_EVENT"], \
                            label='Cluster ' + str(int(name)))
                    kmf.plot(ax=ax, show_censors=True, ci_show=False)

                plt.title ('P-value = %s' %(round_to_1(test_stats.p_value)))
                plt.xlabel('Time (days)');

                plt.savefig(coca_results_dir+'/survival_analysis_plot')

                file= open(coca_results_dir+'/log.txt', 'w')
                file.write(f'survival_analysis_pval\t{test_stats.p_value}\n')
                file.write(f'num_clusters\t{num_cluster}\n')
                file.write(f'network_influence\t{network_influence}\n')
                file.write(f'network_type\t{network_type}\n')

    #file_merge= open(OUTPUT_DATA_DIR_PATH+'/stats_merged', 'w')
    ctr = -1
    df_global= None
    for num_cluster in num_clusters:
        for (network_influence, network_type) in merge_nwtype_nwInf:
            ctr= ctr+1
            OUTPUT_DATA_DIR_PATH_ = os.path.join(OUTPUT_DATA_DIR_PATH, str(ctr))

            cluster_result_paths= OrderedDict([
            ('GeneExpr', os.path.join(OUTPUT_DATA_DIR_PATH_, 'clustering_gene')),
            ('SomaMut', os.path.join(OUTPUT_DATA_DIR_PATH_, 'clustering_mut')), 
            ('miR', os.path.join(OUTPUT_DATA_DIR_PATH_, 'clustering_miR'))])

            ind= -1
            while ind < len(list(cluster_result_paths.keys())):
                if ind == -1:
                    tag= 'allOmics'
                else:
                    tag= list(cluster_result_paths.keys())[ind]
                ind= ind+1
                # assemble the raw inputs into a single file formatted like an omics file
                coca_results_dir= os.path.join(OUTPUT_DATA_DIR_PATH_, 'coca-'+tag)
                try:
                    df= pd.read_csv(coca_results_dir+'/log.txt', sep= '\t', index_col= 0)
                    df = df.T
                    df['run_set']= ctr
                    df['coca_type']= tag
                    #if ctr ==1:
                    if df_global is None:
                        df_global= df
                    else:
                        df_global= pd.concat([df_global, df], axis= 0)        

                except:
                    continue


    df_global.to_csv(OUTPUT_DATA_DIR_PATH+'/stats.txt', sep= '\t', index_label= 'survival_analysis_pval')
